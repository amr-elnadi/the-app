

# importing libraries
import streamlit as st
import tensorflow as tf
from streamlit_lottie import st_lottie  
from tensorflow.keras.applications.xception import preprocess_input
import numpy as np
import json
from PIL import Image
from io import BytesIO
import pandas as pd
import requests 
import urllib
from streamlit_image_select import image_select

# set page configuration
st.set_page_config(
    page_title="Image Classification App",
    page_icon="icon.png",
    layout="wide",
    initial_sidebar_state="expanded",
    )


# function to read json files
def load_lottiefile(filepath: str):
    with open(filepath, "r") as f:
        return json.load(f)

# function to access urls    
def load_lottieurl(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

# project title
st.title("A CAD System Based on Deep CNNs for Skin Cancer Detection")

# loading animated graph from url
first_anime = load_lottieurl("https://assets8.lottiefiles.com/packages/lf20_VfWq5Z.json")

# animated graph settings
st_lottie(
    first_anime,
    speed=1,
    reverse=False,
    loop=True,
    quality="low", # medium ; high
    height=300,
    width=300,
    key=None,
)

# introduction about the project
st.subheader('Introduction.')
st.write('This application is to diagnose diseases related to skin from its images. Output is the predicttion generated by the model chosen. For the use of the application, upload your skin image by clicking on upload file button or you can test the performance of the application by choosing the option to try on images sample which can be found on the left bar. additionally, you can choose from 3 different deep learning models to perform the prediction.')
st.write('Accepted format of uploaded images is jpg')
st.write('''
# Dataset Description.
''')

# loading animated graph from json file
second_anime = load_lottiefile("data4.json")

# animated graph settings
st_lottie(
    second_anime,
    speed=1,
    reverse=False,
    loop=True,
    quality="low", # medium ; high
    height=300,
    width=800,
    key=None,
)

# dataset describtion
st.write('The dataset used to train the models is the augmented version of ISIC 2019. the dataset consists of almost 89,000 skin images belonging to 8 different classes. The 8 classes are NV, MEL, VASC, BCC, BKL, DF, AK and SCC. These classses are common benign skin diseases except MEl which is malignant or skin cancer. Classes scientific names are NV for nevus, MEL for melanoma, VASC for vascular lesion, BCC for basal cell carcinoma, BKL for benign keratosis, DF for dermatofibroma, AK for actinic keratosis and SCC for squamous cell carcinoma. DIstribution of number of images per class is different from class to another as shown in the figure below.') 
st.image('data_full.png', width=400)
st.write('For this project, training has been done on 36,000 images, 4,500 image from each class. This can be shown in the figure below.')
st.image('data_after.png', width=400)           
st.sidebar.subheader("Options")
models_list = ["Xception", "EffecientNetB5", "VGG19"]
network = st.sidebar.selectbox("Select the Model", models_list)

# caching and loading models' weights
@st.cache(allow_output_mutation=True)
def get_model(model_name):
    load = tf.keras.models.load_model(model_name)
    return (load)

model_1 = get_model('Xcep_multi290_new.hdf5')  # assigning Xception model to model_1 variable
model_2 = get_model('EFNETB5_model.hdf5')      # assigning EffNet model to model_2 variable
model_3 = get_model('VGG_model.hdf5')          # assigning VGG model to model_3 variable

# define a dictionary that maps models names to their classes
MODELS = {
    "Xception": model_1,
    "EffecientNetB5": model_2,
    "VGG19": model_3
}


# creating upload button 
uploaded_file = st.sidebar.file_uploader(
    "Choose an image to classify", type=["jpg"]
)

model = MODELS[network]
class_names = {0: 'Melanocytic Nevi',
               1: 'Basal Cell Carcinoma',
               2: 'Actinic Keratosis',
               3: 'Benign Keratosis',
               4: 'Dermatofibroma',
               5: 'Vascular Lesion',
               6: 'Squamous Cell Carcinoma ',
               7: 'Melanoma' }  

class_list = ['Melanocytic Nevi', 'Basal Cell Carcinoma', 'Actinic Keratosis', 'Benign Keratosis', 'Dermatofibroma', 'Vascular Lesion', 'Squamous Cell Carcinoma ', 'Melanoma']

# processing the prediction only if an image is uploaded
if uploaded_file:
    bytes_data = uploaded_file.read()

    inputShape = (224, 224)          # EffNet and VGG models input shape
    preprocess = preprocess_input

    if network in ("Xception"):
        inputShape = (290, 290)      # Xception model input shape
        preprocess = preprocess_input


    # image preprocessing
    image = Image.open(BytesIO(bytes_data))
    image = image.convert("RGB")
    image = image.resize(inputShape)
    image = tf.keras.preprocessing.image.img_to_array(image)
    image = np.expand_dims(image, axis=0)
    image /= 255.

    # predicting on selected image 
    preds = model.predict(image)  
    index = np.argmax(preds)             # assigning highest class's propability to a variable  
    st.image(bytes_data, width=400)
    s = pd.Series(preds[0],index=class_list)
    df = pd.DataFrame(s, columns=['confidence'])   # creating dataframe of classes' propabilities 
    st.title("Prediction - {}".format(class_names[index])) 

# checkbox to use images samples    
if st.sidebar.checkbox("try on image sample"):
    img = image_select(
    label="Select an image",
    images=[
        "ISIC_NV.jpg",
        "ISIC_MEL.jpg",
        'ISIC_BKL.jpg',
        'ISIC_AK.jpg',
        'ISIC_BCC.jpg',
        'ISIC_DF.jpg',
        'ISIC_VASC.jpg',
        'ISIC_SCC.jpg',
    ],
    captions=["NV", "MEL", "BKL", "AK", "BCC", "DF", "VASC", "SCC"],
     use_container_width=False)
    st.image(img, width=400)

    inputShape = (224, 224)           # EffNet and VGG models input shape
    preprocess = preprocess_input

    if network in ("Xception"):
        inputShape = (290, 290)       # Xception model input shape
        preprocess = preprocess_input

    # image preprocessing
    image = Image.open(img)
    image = image.convert("RGB")
    image = image.resize(inputShape)
    image = tf.keras.preprocessing.image.img_to_array(image)
    image = np.expand_dims(image, axis=0)
    image /= 255.

    # predicting on selected image 
    preds = model.predict(image)
    index = np.argmax(preds)          # assigning highest class's propability to a variable 
    s = pd.Series(preds[0],index=class_list)
    df = pd.DataFrame(s, columns=['confidence'])     # creating dataframe of classes' propabilities 
    st.title("Prediction - {}".format(class_names[index]))

# checkbox to show the top 5 predictions    
if st.sidebar.checkbox("show top 5 predictions"):
    st.subheader(f"Top Predictions from {network} model")
    st.dataframe(
        df.sort_values(by=['confidence'], ascending=False).head(5)
        )

# checkbox to show model's classification report    
if st.sidebar.checkbox("Show classification report"):

    if network in ("Xception"):
        st.image('Xcep_metrics.PNG', width=400, caption='Xception model classification report')

    elif network in ("EffecientNetB5"):
        st.image('efn_metrics.PNG', width=400, caption='EffecientNetB5 model classification report')

    else:
        st.image('VGG_metrics.PNG', width=400, caption='VGG19 model classification report')

# checkbox to show model's confusion matrix 
if st.sidebar.checkbox("Show confusion matrix"):

    if network in ("Xception"):
        st.image('Xcep_cnf.png', width=400, caption='Xception model Confusion Matrix')

    elif network in ("EffecientNetB5"):
        st.image('efn_cnf.png', width=400, caption='EffecientNetB5 model Confusion Matrix')

    else:
        st.image('VGG_cnf.png', width=400, caption='VGG19 model Confusion Matrix')

